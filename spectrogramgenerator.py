# -*- coding: utf-8 -*-
"""SpectrogramGenerator.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q1a4gSvbcf6fn3r0tFyVEgqTErXVvZYM

### This notebook contains my code for generating spectrograms for each of the audio splits, at the bottom. Most of the file is experimentation code exploring the relevant libraries such as librosa and Audio.
"""

! pip install librosa

!pip install pydub librosa music21

pip install torchvision

! pip install mir_eval

import librosa
import librosa.display as dsp
#import mir_eval
from librosa import display as librosadisplay
from IPython.display import Audio
import matplotlib.pyplot as plt
import numpy as np
import time
import warnings
import soundfile as sf
warnings.filterwarnings('ignore')

from google.colab.patches import cv2_imshow

import librosa
import librosa.display as dsp
from librosa import display as librosadisplay
from IPython.display import Audio
import matplotlib.pyplot as plt
import numpy as np
import time
import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import os

from IPython.display import Audio, Javascript
from scipy.io import wavfile
from pydub import AudioSegment

import torch
from google.colab import files
from matplotlib.pyplot import figure

import random
from PIL import Image
import cv2
import pickle

from google.colab import drive
drive.mount('/content/drive')

selected_ragas = ['Ahiri', 'Abheri', 'amrutavarSiNi', 'Anandabhairavi', 'AndOLikA', 'Arabhi', 'asAvEri', 'aThANA', 'bahudAri', 'balahamsa', 'bauLi', 'bEgaDA', 'behAg', 'bhairavi', 'bhUpaLaM', 'bilahari', 'bindumAlini', 'bowLi', 'brundAvanasArangA', 'BrundAvani', 'cakravAkam', 'candrajyOti', 'cArukEsi', 'cenjuruTi', 'darbAr', 'dEsh', 'dEvagAndhAri', 'dEvamanOhari', 'dhanyAsi', 'dvijAvanti', 'gambhIranATai', 'garuDadhvani', 'gauDamalhAr', 'gauLa', 'gauLipantu', 'ghaNTA', 'hamIrkalyANi', 'hamsadhvani', 'hamsagamini', 'hamsanAdam', 'hamsAnandi', 'hanumatODi', 'harikAmbhOji', 'hEmavati', 'hindOLam', 'husEni', 'jaganmOhini', 'janaranjani', 'jOnpuri', 'kalyANavasantam', 'kalyANi', 'kamalamanOhari', 'kAmavardhani', 'kAmavardhini', 'kAmbhOji', 'kAmbOji', 'kAnaDA', 'kannaDa', 'kannaDagauLa', 'kApi', 'kApinArAyaNi', 'karaharapriya', 'karNaranjani', 'kathanakutUhalam', 'kEdAragauLa', 'kEdAram', 'khamAs', 'kharaharapriyA', 'kIravANi', 'kuntalavarALi', 'kurinji', 'lalitA', 'latAngi', 'madhuvanti', 'madhyamAvati', 'malahari', 'mALavi', 'malayamArutam', 'mAND', 'maNirangu', 'mAnji', 'mAyAmALavagauLa', 'mishrashivaranjani', 'misrashivaranjani', 'mOhanakalyANi', 'mOhanam', 'mukhAri', 'nAdanAmakriyA', 'nAgasvarAvaLi', 'naLinakAnti', 'nArAyaNagauLa', 'nArirItigauLa', 'nATa', 'naTabhairavi', 'nATakapriyA', 'nATTai', 'nATTakurinji', 'navarOj', 'nAyaki', 'nIlAmbari', 'pantuvarALi', 'paraju', 'paras', 'pashupatipriyA', 'punnAgavarALi', 'pUrNacandrikA', 'pUrvikalyANi', 'ranjani', 'ravicandrikA', 'rEvagupti', 'rEvati', 'rItigauLa', 'sahAnA', 'sALagabhairavi', 'sAma', 'sAramati', 'sAranga', 'saurAshtram', 'saurASTra', 'sAvEri', 'shankarAbharaNam', 'shaNmukhapriyA', 'shivaranjani', 'shrI', 'shrIranjani', 'shubhapantuvarALi', 'shuddhadhanyAsi', 'shuddhasAvEri', 'shyAmA', 'simhEndramadhyamam', 'sindubhairavi', 'sourAshTram', 'suraTi', 'tODi', 'vAcaspati', 'valaji', 'varALi', 'vasantA', 'yadukulakAmbhOji', 'yamunAkalyANi']

"""# Code below experiments with Audio package, librosa, generating audio splits etc."""

data1, sample_rate = librosa.load(librosa.example('vibeace', hq=True))
Audio(data=data1,rate=sample_rate)

#audio, sr = librosa.load(file_name)

# Get number of samples for 2 seconds; replace 2 by any number
buffer = 15 * sample_rate

samples_total = len(data1)
samples_wrote = 0
counter = 1

while samples_wrote < samples_total:

    #check if the buffer is not exceeding total samples 
    if buffer > (samples_total - samples_wrote):
        buffer = samples_total - samples_wrote

    block = data1[samples_wrote : (samples_wrote + buffer)]

    pathName = "/content/drive/MyDrive/N240Project/AudioSplits/"
    out_filename = pathName + "split_" + str(counter) + "_" + 'vibeace'

    # Write 15 second segment
    sf.write(out_filename, block, sample_rate, format = 'OGG')
    counter += 1
    samples_wrote += buffer

print('Total number of samples: ',data1.shape[0])
print('Sample rate: ',sample_rate)
print('Length of file in seconds: ',librosa.get_duration(y=data1, sr=sample_rate))

plt.plot(data1)
plt.xlim([2000,3000])

d = librosa.stft(data1)
D = librosa.amplitude_to_db(np.abs(d),ref=np.max)

fig,ax = plt.subplots(2,1,sharex=True,figsize=(10,10))
img = dsp.specshow(D, y_axis='linear', x_axis='s',sr=sample_rate,ax=ax[0])
ax[0].set(title='Linear frequency power spectrogram')
ax[0].label_outer()

dsp.specshow(D,y_axis='log',x_axis='s',sr=sample_rate,ax=ax[1])
ax[1].set(title='Log frequency power spectrogram')
ax[1].label_outer()
fig.colorbar(img, ax=ax, format='%+2.f dB')

"""Chromagram"""

C = np.abs(librosa.stft(data1))
chroma = librosa.feature.chroma_stft(S=C, sr=sample_rate)

fig, ax = plt.subplots(figsize=(10,6))
img = librosa.display.specshow(chroma, y_axis='chroma', x_axis='s', ax=ax)
fig.colorbar(img, ax=ax)
ax.set(title='Chromagram')

"""### Load the ~3500 songs in our dataset"""

directory_path = '/content/drive/MyDrive/N240Project/SP_downloads'
directory_files = os.listdir(directory_path)

df = pd.DataFrame()
i = 0
for file in directory_files:
    i+=1
    print(str(file), i) 
    #df_file = pd.read_csv(os.path.join(directory_path, file), encoding = 'ISO-8859-1',low_memory=False)
    #df = pd.concat([df, df_file])

#open the file

filename = librosa.ex('trumpet')
y, sr = librosa.load(filename)

EXPECTED_SAMPLE_RATE = 16000

uploaded_file_name = "/content/drive/MyDrive/N240Project/RagamSplits1/balahamsa/balahamsa_split_11"

t1 = t1 * 1000 #Works in milliseconds
t2 = t2 * 1000
newAudio = AudioSegment.from_wav("oldSong.wav")
newAudio = newAudio[t1:t2]
newAudio.export('newSong.wav', format="wav")

def convert_audio_for_model(user_file, output_file='converted_audio_file.wav'):
  audio = AudioSegment.from_file(user_file)
  audio = audio.set_frame_rate(EXPECTED_SAMPLE_RATE).set_channels(1)
  audio.export(output_file, format="wav")
  return output_file

# may not need this when running on splits
converted_audio_file = convert_audio_for_model(uploaded_file_name)

sample_rate, audio_samples = wavfile.read(uploaded_file_name, 'rb')

duration = len(audio_samples)/sample_rate
print(f'Sample rate: {sample_rate} Hz')
print(f'Total duration: {duration:.2f}s')
print(f'Size of the input: {len(audio_samples)}')

sample_rate, audio_samples = wavfile.read(converted_audio_file, 'rb')

# Let's listen to the wav file.
Audio(audio_samples, rate=sample_rate)

_ = plt.plot(audio_samples)

MAX_ABS_INT16 = 32768.0

def plot_stft(x, sample_rate, show_black_and_white=False):
  x_stft = np.abs(librosa.stft(x, n_fft=2048))
  fig, ax = plt.subplots()
  fig.set_size_inches(10, 5)
  x_stft_db = librosa.amplitude_to_db(x_stft, ref=np.max)
  if(show_black_and_white):
    librosadisplay.specshow(data=x_stft_db, y_axis='log', 
                             sr=sample_rate, cmap='gray_r')
  else:
    librosadisplay.specshow(data=x_stft_db, y_axis='log', sr=sample_rate)

  plt.colorbar(format='%+2.0f dB')

plot_stft(audio_samples / MAX_ABS_INT16 , sample_rate=EXPECTED_SAMPLE_RATE)
plt.show()

MAX_ABS_INT16 = 32768.0

x_stft = np.abs(librosa.stft(audio_samples/MAX_ABS_INT16, n_fft=2048))**2

S = librosa.feature.melspectrogram(S=x_stft)

powerS = librosa.power_to_db(S, ref=np.max)

type(S)

S[0][0]

powerS[0][0]

arr = np.array(S)
arr

type(arr)

arr.shape

new_shape = (256,256)

resized_arr = cv2.resize(arr, new_shape)

resized_arr.shape

resized_arr[0]

"""# Plotting mel spectrogram manually without librosa"""

cv2_imshow(resized_arr)

"""# Now we scale the decibels with librosa and use the built in display function"""

displayIMG = librosa.power_to_db(resized_arr, ref=np.max)

displayIMG[0]

cv2_imshow(displayIMG)

fig, ax = plt.subplots()

librosa.display.specshow(displayIMG, fmax=8000, ax=ax)

plt.rcParams['savefig.transparent'] = False

plt.rcdefaults()

plt.rcParams['axes.edgecolor'] = 'none' # Set the edge color to white
#plt.rcParams['figure.facecolor'] = 'black' # Set the background color of the figure to black
plt.rcParams['figure.edgecolor'] = 'none'

fig, ax = plt.subplots()
fig.set_size_inches(2.56, 2.56)
librosa.display.specshow(librosa.power_to_db(S, ref=np.max), fmax=8000, ax=ax)# frame = False, border = False)
images_dir = '/content/drive/MyDrive/N240Project/ExamplePics/try4' 
plt.savefig(images_dir)

dpi = ax.figure.get_dpi()
width, height = ax.figure.get_size_inches()
pixels_width, pixels_height = int(width * dpi), int(height * dpi)
print(f"The plot has {pixels_width} x {pixels_height} pixels")

"""## Librosa generated mel spectrogram"""

fig, ax = plt.subplots()

librosa.display.specshow(librosa.power_to_db(resized_arr, ref=np.max), fmax=8000, ax=ax)

dpi = ax.figure.get_dpi()
width, height = ax.figure.get_size_inches()
pixels_width, pixels_height = int(width * dpi), int(height * dpi)
print(f"The plot has {pixels_width} x {pixels_height} pixels")

balahamsaSpectrogram = torch.from_numpy(S)

print(balahamsaSpectrogram.shape)
#print(sample_rate)
#print(dur)

"""# Example mel spectrogram on a Carnatic split"""

img = Image.open('/content/drive/MyDrive/N240Project/ExamplePics/try1.png')
img.show()

img.size

"""## Function below creates mel spectrogram for a given audio split"""

MAX_ABS_INT16 = 32768.0
EXPECTED_SAMPLE_RATE = 16000


def MELplot_stft(x, sample_rate):#, ragam, filename):

  x_stft = np.abs(librosa.stft(x, n_fft=2048))**2

  S = librosa.feature.melspectrogram(S=x_stft)
  
  S = librosa.power_to_db(S, ref=np.max)

  new_shape = (256,256)

  resized_arr = cv2.resize(S, new_shape)

  return resized_arr

mohanam_directory_path = '/content/drive/MyDrive/N240Project/RagamSplits3/mohanam/'
mohanam_directory_files = os.listdir(mohanam_directory_path)
mohanam_pickle_path = '/content/drive/MyDrive/N240Project/pickleFiles/'

"""## Generate pickle files with all mel spectrograms and labels for mohanam. Manually repeat for the other 9 ragams in pool."""

MAX_ABS_INT16 = 32768.0
EXPECTED_SAMPLE_RATE = 16000

pickle_file = os.path.join(mohanam_pickle_path, 'mohanam.pickle')

with open(pickle_file, 'wb') as f:
    X=[]
    y=[]
    for split in mohanam_directory_files:
        print(split)
        splitAudioFile = mohanam_directory_path + "/" + split
        if librosa.get_duration(filename=splitAudioFile) > 9:
            sample_rate, audio_samples = wavfile.read(splitAudioFile, 'rb')
            melSpec = MELplot_stft(audio_samples/MAX_ABS_INT16, sample_rate=EXPECTED_SAMPLE_RATE)
            X.append(melSpec)
            y.append('mohanam')
    pickle.dump((X, y), f)

bhupalam_directory_path = '/content/drive/MyDrive/N240Project/RagamSplits1/bhupalam/'
bhupalam_directory_files = os.listdir(bhupalam_directory_path)
bhupalam_pickle_path = '/content/drive/MyDrive/N240Project/pickleFiles/'

MAX_ABS_INT16 = 32768.0
EXPECTED_SAMPLE_RATE = 16000

pickle_file = os.path.join(bhupalam_pickle_path, 'bhupalam.pickle')

with open(pickle_file, 'wb') as f:
    X=[]
    y=[]
    for split in bhupalam_directory_files:
        print(split)
        splitAudioFile = bhupalam_directory_path + "/" + split
        if librosa.get_duration(filename=splitAudioFile) > 9:
            sample_rate, audio_samples = wavfile.read(splitAudioFile, 'rb')
            melSpec = MELplot_stft(audio_samples/MAX_ABS_INT16, sample_rate=EXPECTED_SAMPLE_RATE)
            X.append(melSpec)
            y.append('bhupalam')
    pickle.dump((X, y), f)

MAX_ABS_INT16 = 32768.0
EXPECTED_SAMPLE_RATE = 16000

revaguptiSplitPath = '/content/drive/MyDrive/N240Project/RagamSplits1/revagupti'

revaguptiSplits = os.listdir(revaguptiSplitPath)

for split in revaguptiSplits:
    print(split)
    splitAudioFile = revaguptiSplitPath + "/" + split
    sample_rate, audio_samples = wavfile.read(splitAudioFile, 'rb')
    #only do if over 10 secs
    if librosa.get_duration(filename=splitAudioFile) > 9:
        MELplot_stft(audio_samples/MAX_ABS_INT16 , sample_rate=EXPECTED_SAMPLE_RATE, ragam='revagupti', filename=split)